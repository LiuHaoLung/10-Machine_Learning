{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serves a lot of use cases when dealing with text or unstructured text data.\n",
    "\n",
    "Imagine you work for google news and you want to group news articles by topic or work for a legal firm and you need to sift through thousands of pages of legal documents to find relevent ones, this is where NLP can help.\n",
    "___\n",
    "#### What is Natural Language Processing want to do ?\n",
    "\n",
    "We will want to compile the documents in some fashion get features from them so we'll have to featuritis those documents and then compare theri features.\n",
    "\n",
    "* Compile Documents means.\n",
    "* Featurize Them.\n",
    "* Compare their features.\n",
    "___\n",
    "#### Simple example：\n",
    "\n",
    "There are two documents：\n",
    "\n",
    "* One is 'Blue House'\n",
    "* Another is 'Red House'\n",
    "\n",
    "Featurize based on word count：(it can transform documents into a vectorized word counts, and count how many times those words occur in each document)\n",
    "\n",
    "* 'Blue House' = (red,blue,house) = (0,1,1)\n",
    "* 'Red House' = (red,blue,house) = (1,0,1)\n",
    "\n",
    "A document represented as a vector of word counts is called 'Bag of Words', can use cosine similarity on the vectors made to determine similarity.\n",
    "\n",
    "These is really useful because basically treating each document as a vector of features meaning can perform mathematical operations such as the cosine similarity taking theri dot products and then dividing it by the multiplication of their magnitudes or other similarity metrics in order to figure out how similar two text documents are to each other.\n",
    "___\n",
    "#### How to improve Bag of Words ?\n",
    "\n",
    "1. Adjusting word counts based on their frequency in corpus(the group of all the documents).\n",
    "2. Can use TF-IDF(Term Frequency-Inverse Document Frequency).\n",
    "___\n",
    "#### What is TF-IDF ?\n",
    "\n",
    "TF：means importance of the term within that document.\n",
    "\n",
    "* TF(d,t)：\n",
    "    1. d means documents.\n",
    "    2. t means the number of occurrences of term.\n",
    "\n",
    "IDF：importance of the term in the corpus itself.\n",
    "\n",
    "* IDF(t) = log(D/t)\n",
    "    1. D means total number of documents.\n",
    "    2. t means the number of documents with the term.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
