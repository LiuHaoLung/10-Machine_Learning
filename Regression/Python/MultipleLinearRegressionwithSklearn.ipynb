{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('1.02. Multiple linear regression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Rand 1,2,3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1714</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1664</td>\n",
       "      <td>2.52</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1760</td>\n",
       "      <td>2.54</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1685</td>\n",
       "      <td>2.74</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1693</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SAT   GPA  Rand 1,2,3\n",
       "0  1714  2.40           1\n",
       "1  1664  2.52           3\n",
       "2  1760  2.54           3\n",
       "3  1685  2.74           3\n",
       "4  1693  2.83           2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Rand 1,2,3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1845.273810</td>\n",
       "      <td>3.330238</td>\n",
       "      <td>2.059524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>104.530661</td>\n",
       "      <td>0.271617</td>\n",
       "      <td>0.855192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1634.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1772.000000</td>\n",
       "      <td>3.190000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1846.000000</td>\n",
       "      <td>3.380000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1934.000000</td>\n",
       "      <td>3.502500</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2050.000000</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SAT        GPA  Rand 1,2,3\n",
       "count    84.000000  84.000000   84.000000\n",
       "mean   1845.273810   3.330238    2.059524\n",
       "std     104.530661   0.271617    0.855192\n",
       "min    1634.000000   2.400000    1.000000\n",
       "25%    1772.000000   3.190000    1.000000\n",
       "50%    1846.000000   3.380000    2.000000\n",
       "75%    1934.000000   3.502500    3.000000\n",
       "max    2050.000000   3.810000    3.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample is the machine learning word for observation\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[['SAT','Rand 1,2,3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['GPA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00165354, -0.00826982])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it is the coefficient of the SAT and the Rand 1,2,3\n",
    "# they are ordered in the way we fed them\n",
    "# the 0.0016 corresponds to SAT\n",
    "# the -0.0083 corresponds to Rand 1,2,3\n",
    "\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29603261264909486"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4066811952814285"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the R-squared is a universal measure to evaluate how well linear regression fare and compare\n",
    "\n",
    "reg.score(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Adjusted R-squared\n",
    "\n",
    "The adjusted R-squared is much more appropriate measure for a multiple linear regression.\n",
    "\n",
    "The adjusted R-squared steps on the R-squared and adjusts for the number of variables included in the model.\n",
    "\n",
    "There is no adjusted R-squared methods in the package.\n",
    "\n",
    "The Adjusted R-squared formule is:\n",
    "\n",
    "$R^2{adj.} = 1 - (1-R^2)*\\frac{n-1}{n-p-1}$\n",
    "\n",
    "In this formula, n = 84, it means the number of observations; the p = 2, it means the number of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = reg.score(x,y)\n",
    "\n",
    "n = x.shape[0]\n",
    "p = x.shape[1]\n",
    "\n",
    "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39203134825134023"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the adjusted R-squared is lower than R-squared\n",
    "# therefore one or more of the predictors have littel or no explanatory power\n",
    "\n",
    "adjusted_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Through the adjusted R-squared, it can one of the two variables doesn't increase the explanatory power of the regression, therefore if we can identify which one and remove it we would further simplify this model.\n",
    "___\n",
    "\n",
    "How to detect the variables which are unneded in a model ?\n",
    "\n",
    "There's actually a whole process created for this purpose, it is called feature selection, feature selection is a very important procedure in machine learning as it simplifies models which makes them much easier to interpret by data scientists.\n",
    "\n",
    "Feature selection simplifies models, improve speed and often prevent a series of unwanted issues arising from having too many features.\n",
    "___\n",
    "\n",
    "Through the p-value can determine whether the independent variables were relevant for the model, if a p-value > 0.05, we can disregard it.\n",
    "\n",
    "How can we find the p-value in sklearn, the sklearn as a machine learning package rather than statistics one, so there is no built in method we can call to get p-value.\n",
    "\n",
    "Therefore we must find a work around a very close concept is available with the feature selection module from sklearn, it is called f-regression, f-regression creates simple linear regressions of each feature and the depedent variable, for this GPA and SAT example, it would translate into two regressions, one where we predict GPA with SAT and the other where we predict GPA with Rand 1,2,3.\n",
    "\n",
    "Then the method would calculate the F-statistic for each of those regressions and return the respective p-values.\n",
    "\n",
    "If there were 50 features, 50 simple regression would be created.\n",
    "\n",
    "For a simple regression the p-value of the F-statistic coincides with the p-value of the only independent variable, therefore this method is precisely what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([56.04804786,  0.17558437]), array([7.19951844e-11, 6.76291372e-01]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the output are all arrays\n",
    "# the first one contains the F-statistics for each of the regressions\n",
    "# the second one contains the p-value\n",
    "# generally we are interested only in the p-value\n",
    "\n",
    "f_regression(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = f_regression(x,y)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.19951844e-11, 6.76291372e-01])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it is scientific notation\n",
    "# e-11 means *10^-11 or /10^11\n",
    "# e-1 means *10^-1 or /10^1\n",
    "\n",
    "p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.676])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first p-value refers to the first column of SAT\n",
    "# the second p-value refers to the second column of Rand 1,2,3\n",
    "# so the p-value of SAT is 0.000\n",
    "# the p-value of Rand 1,2,3 is 0.676\n",
    "# in this case the SAT is useful variable while Rand 1,2,3 is useless\n",
    "# there are the univariate p-values reached from simple linear models\n",
    "# they don't reflect the interconnection of the features in our multiple linear regression\n",
    "# there f-regression should be used with caution\n",
    "\n",
    "p_values.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_summary = pd.DataFrame(data = x.columns.values, columns = ['Features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Rand 1,2,3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features\n",
       "0         SAT\n",
       "1  Rand 1,2,3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_summary['Coefficients'] = reg.coef_\n",
    "reg_summary['p-value'] = p_values.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficients</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SAT</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Rand 1,2,3</td>\n",
       "      <td>-0.008270</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features  Coefficients  p-value\n",
       "0         SAT      0.001654    0.000\n",
       "1  Rand 1,2,3     -0.008270    0.676"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# through the p-value we can know the Rand 1,2,3 should be removed\n",
    "# p-values are one of the best ways to determine if a variable is redundant\n",
    "# but they provide no information whatsoever about how useful a variable is\n",
    "# maybe both p-value are all 0.000 but this doesn't mean they are equally important\n",
    "\n",
    "reg_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "The most common problem in working with numerical data is the difference in magnitudes.\n",
    "\n",
    "An easy fix for this issue is standardization also know as feature scaling or normalization.\n",
    "\n",
    "However normalization could also refet to a few additional concepts within machine learning.\n",
    "\n",
    "Standardization or feature scaling is the process of transforming data into a standard scale.\n",
    "\n",
    "This translates to subtracting the mean and dividing by the standard deviation.\n",
    "\n",
    "In this way, we will obtain a distribution with a mean of 0 and standard deviation of 1 which could easily be proven.\n",
    "\n",
    "Through the standarization, it can forced of very different scales to appear similar.\n",
    "\n",
    "Use the feature scaling can ensure linear regressions treat the two variables equally and it is much easier to make sense of the data.\n",
    "\n",
    "There are different strategies to deal with different magnitudes, however standardization is probably the most common one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[['SAT','Rand 1,2,3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['GPA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler be used to sclae our data\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit can calculates and stores the mean and standard deviation of each feature\n",
    "\n",
    "scaler.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.26338288, -1.24637147],\n",
       "       [-1.74458431,  1.10632974],\n",
       "       [-0.82067757,  1.10632974],\n",
       "       [-1.54247971,  1.10632974],\n",
       "       [-1.46548748, -0.07002087],\n",
       "       [-1.68684014, -1.24637147],\n",
       "       [-0.78218146, -0.07002087],\n",
       "       [-0.78218146, -1.24637147],\n",
       "       [-0.51270866, -0.07002087],\n",
       "       [ 0.04548499,  1.10632974],\n",
       "       [-1.06127829,  1.10632974],\n",
       "       [-0.67631715, -0.07002087],\n",
       "       [-1.06127829, -1.24637147],\n",
       "       [-1.28263094,  1.10632974],\n",
       "       [-0.6955652 , -0.07002087],\n",
       "       [ 0.25721362, -0.07002087],\n",
       "       [-0.86879772,  1.10632974],\n",
       "       [-1.64834403, -0.07002087],\n",
       "       [-0.03150724,  1.10632974],\n",
       "       [-0.57045283,  1.10632974],\n",
       "       [-0.81105355,  1.10632974],\n",
       "       [-1.18639066,  1.10632974],\n",
       "       [-1.75420834,  1.10632974],\n",
       "       [-1.52323165, -1.24637147],\n",
       "       [ 1.23886453, -1.24637147],\n",
       "       [-0.18549169, -1.24637147],\n",
       "       [-0.5608288 , -1.24637147],\n",
       "       [-0.23361183,  1.10632974],\n",
       "       [ 1.68156984, -1.24637147],\n",
       "       [-0.4934606 , -0.07002087],\n",
       "       [-0.73406132, -1.24637147],\n",
       "       [ 0.85390339, -1.24637147],\n",
       "       [-0.67631715, -1.24637147],\n",
       "       [ 0.09360513,  1.10632974],\n",
       "       [ 0.33420585, -0.07002087],\n",
       "       [ 0.03586096, -0.07002087],\n",
       "       [-0.35872421,  1.10632974],\n",
       "       [ 1.04638396,  1.10632974],\n",
       "       [-0.65706909,  1.10632974],\n",
       "       [-0.13737155, -0.07002087],\n",
       "       [ 0.18984542,  1.10632974],\n",
       "       [ 0.04548499, -1.24637147],\n",
       "       [ 1.1618723 ,  1.10632974],\n",
       "       [-1.37887123, -1.24637147],\n",
       "       [ 1.39284898, -1.24637147],\n",
       "       [ 0.76728713, -0.07002087],\n",
       "       [-0.20473975, -0.07002087],\n",
       "       [ 1.06563201, -1.24637147],\n",
       "       [ 0.11285319, -1.24637147],\n",
       "       [ 1.28698467,  1.10632974],\n",
       "       [-0.41646838,  1.10632974],\n",
       "       [ 0.09360513, -1.24637147],\n",
       "       [ 0.59405462, -0.07002087],\n",
       "       [-2.03330517, -0.07002087],\n",
       "       [ 0.32458182, -1.24637147],\n",
       "       [ 0.40157405, -1.24637147],\n",
       "       [-1.10939843, -0.07002087],\n",
       "       [ 1.03675993, -1.24637147],\n",
       "       [-0.61857297, -0.07002087],\n",
       "       [ 0.44007016, -0.07002087],\n",
       "       [ 1.14262424, -1.24637147],\n",
       "       [-0.35872421,  1.10632974],\n",
       "       [ 0.45931822,  1.10632974],\n",
       "       [ 1.88367444,  1.10632974],\n",
       "       [ 0.45931822, -1.24637147],\n",
       "       [-0.12774752, -0.07002087],\n",
       "       [ 0.04548499,  1.10632974],\n",
       "       [ 0.85390339, -0.07002087],\n",
       "       [ 0.15134931, -0.07002087],\n",
       "       [ 0.8250313 ,  1.10632974],\n",
       "       [ 0.84427936,  1.10632974],\n",
       "       [-0.64744506, -1.24637147],\n",
       "       [ 1.24848856, -1.24637147],\n",
       "       [ 0.85390339,  1.10632974],\n",
       "       [ 1.69119387,  1.10632974],\n",
       "       [ 1.6334497 ,  1.10632974],\n",
       "       [ 1.46021718, -1.24637147],\n",
       "       [ 1.68156984, -0.07002087],\n",
       "       [-0.02188321,  1.10632974],\n",
       "       [ 0.87315144,  1.10632974],\n",
       "       [-0.33947615, -1.24637147],\n",
       "       [ 1.3639769 ,  1.10632974],\n",
       "       [ 1.12337618, -1.24637147],\n",
       "       [ 1.97029069, -0.07002087]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the whole steps the whole data has been standardized\n",
    "# having all inputs with the same magnitude allows us to compart their impact\n",
    "\n",
    "x_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(x_scaler,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.17181389, -0.00703007])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.330238095238095"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights will include the intercept and two coefficients\n",
    "\n",
    "reg_summary = pd.DataFrame([['Intercept'],['SAT'],['Rand 1,2,3']], columns = ['Features'])\n",
    "reg_summary['Weights'] = reg.intercept_, reg.coef_[0], reg.coef_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Intercept</td>\n",
       "      <td>3.330238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SAT</td>\n",
       "      <td>0.171814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Rand 1,2,3</td>\n",
       "      <td>-0.007030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features   Weights\n",
       "0   Intercept  3.330238\n",
       "1         SAT  0.171814\n",
       "2  Rand 1,2,3 -0.007030"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights is a the machine learning word for coefficients\n",
    "# we have standardized the features which resulted in standardized coefficients or weights\n",
    "# the bigger the weight, the bigger the impact of the feature of the regression\n",
    "# the machine learning word for intercept is bias\n",
    "# the intercept is nothing but a number which adjusted our regression with some constant\n",
    "# if we need to adjust our regression with some constant then the regression is biased by that number\n",
    "\n",
    "reg_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_summary = pd.DataFrame([['Bias'],['SAT'],['Rand 1,2,3']], columns = ['Features'])\n",
    "reg_summary['Weights'] = reg.intercept_, reg.coef_[0], reg.coef_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Bias</td>\n",
       "      <td>3.330238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SAT</td>\n",
       "      <td>0.171814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Rand 1,2,3</td>\n",
       "      <td>-0.007030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features   Weights\n",
       "0        Bias  3.330238\n",
       "1         SAT  0.171814\n",
       "2  Rand 1,2,3 -0.007030"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the close a weight is to 0, the smaller its impact\n",
    "# the bigger the weight, the bigger its impact\n",
    "# the weight of SAT is much much bigger than Rand 1,2,3\n",
    "# this brings us to feature selection through standardization\n",
    "# we can clearly see that Rand 1,2,3 barely contributes to our output if at all\n",
    "\n",
    "reg_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that Rand 1,2,3 barely contributes to our output if at all, it will make little difference if we remove it from the model or leave it there with a weight of almost 0.\n",
    "\n",
    "This concept is quite remarkable, when we perform feature scaling, we don't really care if a useless variable is there or not.\n",
    "\n",
    "This is also one of the main reasons why sklearn doesn't natively support p-value since most perform some kine of feature scaling before fitting a model, we don't really need to identify the worst performing features, they are automatically penalized by having a very small weight.\n",
    "\n",
    "In general it always prefer to leave out the worst perfoming features as they interact with the useful ones and may bias the weights even if only slightly so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict values using standardized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame(data = [[1700,2], [1800,1]], columns = ['SAT','Rand 1,2,3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>Rand 1,2,3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SAT  Rand 1,2,3\n",
       "0  1700           2\n",
       "1  1800           1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([295.39979563, 312.58821497])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is not the GPA\n",
    "# the reason is the regression model now is trained on standardized inputs\n",
    "# it expected values that are of the same magnitude as the ones used in the trained process\n",
    "# so the new data should be arranged in the same way and also must be standardized in the same way\n",
    "# in the same mean and standard deviation\n",
    "\n",
    "reg.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_scaled = scaler.transform(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.39811928, -0.07002087],\n",
       "       [-0.43571643, -1.24637147]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with the scaler.transform the new_data\n",
    "# this data in the array which contains are standardized data\n",
    "\n",
    "new_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.09051403, 3.26413803])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so it is the right predict\n",
    "\n",
    "reg.predict(new_data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if removed the Rand 1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_simple = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the SAT column\n",
    "\n",
    "x_simple_matrix = x_scaler[:,0].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_simple.fit(x_simple_matrix,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.08970998, 3.25527879])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the same it is only the SAT column\n",
    "# it get the same results all the same 3.09 and 3.26\n",
    "# when we apply the feature scaling it often doesn't affect the final result\n",
    "# if we keep or leave out in significant features\n",
    "# the weights will be so close to zero that they will barely influence the predictions\n",
    "\n",
    "reg_simple.predict(new_data_scaled[:,0].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
